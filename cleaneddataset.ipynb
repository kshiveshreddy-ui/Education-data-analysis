{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6dd919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaning complete!\n",
      "Summary:\n",
      "total_rows: 357405\n",
      "total_columns: 69\n",
      "missing_values: 0\n",
      "year_range: (1970, 2100)\n",
      "top_indicators: {}\n",
      "Cleaned file saved as cleaned_EdStatsData.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### ============================================\n",
    " #PGE1 AI Clinic - Educational Data Analysis\n",
    " #End-to-end data cleaning + analysis notebook\n",
    " #PERSON: Kothapally SHIVESH REDDY\n",
    " #============================================\n",
    "#\n",
    " #---------- Setup ----------\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"EdStatsData.csv\", low_memory=False)\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.replace(\"\\ufeff\", \"\", regex=False)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[\\\\s/]+\", \"_\", regex=True)\n",
    "    .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "#  Remove empty columns and duplicate rows\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "#  Trim whitespace in text columns\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "\n",
    "year_cols = [c for c in df.columns if c.isdigit()]\n",
    "for col in year_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "#  Drop rows missing critical keys\n",
    "if 'country_code' in df.columns and 'indicator_code' in df.columns:\n",
    "    df = df.dropna(subset=['country_code', 'indicator_code'])\n",
    "\n",
    "#  Drop rows completely empty across all year columns\n",
    "df = df.dropna(how='all', subset=year_cols)\n",
    "\n",
    "# Fill missing text fields with 'Unknown'\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Fill numeric columns with 0\n",
    "for col in year_cols:\n",
    "    df[col].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "summary = {\n",
    "    \"total_rows\": len(df),\n",
    "    \"total_columns\": len(df.columns),\n",
    "    \"missing_values\": df.isnull().sum().sum(),\n",
    "    \"year_range\": (min(map(int, year_cols)), max(map(int, year_cols))) if year_cols else None,\n",
    "    \"top_indicators\": df['indicator_name'].value_counts().head(5).to_dict() if 'indicator_name' in df.columns else {}\n",
    "}\n",
    "\n",
    "print(\" Cleaning complete!\")\n",
    "print(\"Summary:\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "df.to_csv(\"cleaned_EdStatsData.csv\", index=False)\n",
    "print(\"Cleaned file saved as cleaned_EdStatsData.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c08f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows missing 'indicator_code'.\n",
      " cleaned_EdStatsSeries.csv saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "#  Helpers in my project \n",
    "def standardize_columns(df):\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "        .str.replace(\"\\ufeff\", \"\", regex=False)\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[\\s/]+\", \"_\", regex=True)\n",
    "        .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def rename_to(df, target_name, candidates):\n",
    "    \"\"\"Rename the first existing candidate column to target_name; return df and the resolved name or None.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            if c != target_name:\n",
    "                df = df.rename(columns={c: target_name})\n",
    "            return df, target_name\n",
    "    return df, None\n",
    "\n",
    "df = pd.read_csv(\"EdStatsSeries.csv\", low_memory=False)\n",
    "\n",
    "# Clean basics \n",
    "df = standardize_columns(df)\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Trim whitespace\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Ensure critical key: indicator_code (from series_code or similar)\n",
    "df, key = rename_to(df, \"indicator_code\", [\"indicator_code\", \"series_code\", \"seriescode\", \"code\"])\n",
    "\n",
    "# Drop rows with missing critical key \n",
    "if key:\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=[key])\n",
    "    print(f\"Dropped {before - len(df)} rows missing '{key}'.\")\n",
    "\n",
    "# --- Fill NaNs in non-critical text columns ---\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "#  Save\n",
    "df.to_csv(\"cleaned_EdStatsSeries.csv\", index=False)\n",
    "print(\" cleaned_EdStatsSeries.csv saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae81336c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows missing 'country_code'.\n",
      " cleaned_EdStatsCountry.csv saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def standardize_columns(df):\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "        .str.replace(\"\\ufeff\", \"\", regex=False)\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[\\s/]+\", \"_\", regex=True)\n",
    "        .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def rename_to(df, target_name, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            if c != target_name:\n",
    "                df = df.rename(columns={c: target_name})\n",
    "            return df, target_name\n",
    "    return df, None\n",
    "\n",
    "df = pd.read_csv(\"EdStatsCountry.csv\", low_memory=False)\n",
    "\n",
    "df = standardize_columns(df)\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Ensure critical key: country_code\n",
    "df, key = rename_to(df, \"country_code\", [\"country_code\", \"countrycode\", \"code\"])\n",
    "\n",
    "if key:\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=[key])\n",
    "    print(f\"Dropped {before - len(df)} rows missing '{key}'.\")\n",
    "\n",
    "# Fill NaNs in non-critical text columns\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "df.to_csv(\"cleaned_EdStatsCountry.csv\", index=False)\n",
    "print(\" cleaned_EdStatsCountry.csv saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "150ff50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows missing ['country_code', 'indicator_code'].\n",
      " cleaned_EdStatsCountrySeries.csv saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def standardize_columns(df):\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "        .str.replace(\"\\ufeff\", \"\", regex=False)\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[\\s/]+\", \"_\", regex=True)\n",
    "        .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def rename_to(df, target_name, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            if c != target_name:\n",
    "                df = df.rename(columns={c: target_name})\n",
    "            return df, target_name\n",
    "    return df, None\n",
    "\n",
    "df = pd.read_csv(\"EdStatsCountry-Series.csv\", low_memory=False)\n",
    "\n",
    "df = standardize_columns(df)\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Ensure keys: country_code & indicator_code\n",
    "df, cc = rename_to(df, \"country_code\", [\"country_code\", \"countrycode\", \"code\"])\n",
    "df, ic = rename_to(df, \"indicator_code\", [\"indicator_code\", \"series_code\", \"seriescode\", \"code\"])\n",
    "\n",
    "# Drop rows missing either key (only if they exist)\n",
    "subset_keys = [k for k in [cc, ic] if k]\n",
    "if subset_keys:\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=subset_keys)\n",
    "    print(f\"Dropped {before - len(df)} rows missing {subset_keys}.\")\n",
    "\n",
    "# Fill NaNs in non-critical text columns\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "df.to_csv(\"cleaned_EdStatsCountrySeries.csv\", index=False)\n",
    "print(\" cleaned_EdStatsCountrySeries.csv saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7af98a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows missing ['country_code', 'indicator_code'].\n",
      " cleaned_EdStatsFootNote.csv saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def standardize_columns(df):\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "        .str.replace(\"\\ufeff\", \"\", regex=False)\n",
    "        .str.lower()\n",
    "        .str.replace(r\"[\\s/]+\", \"_\", regex=True)\n",
    "        .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def rename_to(df, target_name, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            if c != target_name:\n",
    "                df = df.rename(columns={c: target_name})\n",
    "            return df, target_name\n",
    "    return df, None\n",
    "\n",
    "df = pd.read_csv(\"EdStatsFootNote.csv\", low_memory=False)\n",
    "\n",
    "df = standardize_columns(df)\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Ensure keys\n",
    "df, cc = rename_to(df, \"country_code\", [\"country_code\", \"countrycode\", \"code\"])\n",
    "df, ic = rename_to(df, \"indicator_code\", [\"indicator_code\", \"series_code\", \"seriescode\", \"code\"])\n",
    "\n",
    "# Parse 'year' labels like 'YR2001' -> 2001 (if a year-like column exists)\n",
    "# After standardization, the column is usually 'year'\n",
    "if \"year\" in df.columns:\n",
    "    def parse_year(x):\n",
    "        s = str(x)\n",
    "        m = re.search(r\"(\\d{4})\", s)\n",
    "        return int(m.group(1)) if m else pd.NA\n",
    "    df[\"year\"] = df[\"year\"].apply(lambda x: parse_year(x))\n",
    "\n",
    "# Drop rows missing critical keys (country_code, indicator_code)\n",
    "subset_keys = [k for k in [cc, ic] if k]\n",
    "if subset_keys:\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=subset_keys)\n",
    "    print(f\"Dropped {before - len(df)} rows missing {subset_keys}.\")\n",
    "\n",
    "# Fill NaNs in non-critical text columns (e.g., description/notes)\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "df.to_csv(\"cleaned_EdStatsFootNote.csv\", index=False)\n",
    "print(\" cleaned_EdStatsFootNote.csv saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d901e5b6",
   "metadata": {},
   "source": [
    "VERIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc32914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification Report for EdStatsSeries.csv\n",
      "----------------------------------------\n",
      "Column names changed: {'Unnamed: 20', 'Aggregation method', 'Unit of measure', 'Related source links', 'Indicator Name', 'Source', 'Series Code', 'Base Period', 'Related indicators', 'License Type', 'Other web links', 'Long definition', 'General comments', 'Periodicity', 'Development relevance', 'Short definition', 'Other notes', 'Statistical concept and methodology', 'Limitations and exceptions', 'Topic', 'Notes from original source'}\n",
      "Total columns before: 21, after: 15\n",
      "\n",
      "Missing values before cleaning: 55203\n",
      "Missing values after cleaning: 33213\n",
      "\n",
      "Duplicate rows before cleaning: 0\n",
      "Duplicate rows after cleaning: 0\n",
      "\n",
      "Rows before: 3665, after: 3665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "original_file = \"EdStatsSeries.csv\"\n",
    "cleaned_file = \"cleaned_EdStatsSeries.csv\"  # Ensure this exists after cleaning\n",
    "\n",
    "# Loaded both files\n",
    "original_df = pd.read_csv(original_file, low_memory=False)\n",
    "cleaned_df = pd.read_csv(cleaned_file, low_memory=False)\n",
    "\n",
    "# Compared column names\n",
    "original_cols = set(original_df.columns)\n",
    "cleaned_cols = set(cleaned_df.columns)\n",
    "\n",
    "# Missing values count\n",
    "original_missing = original_df.isnull().sum().sum()\n",
    "cleaned_missing = cleaned_df.isnull().sum().sum()\n",
    "\n",
    "# Duplicate rows count\n",
    "original_duplicates = original_df.duplicated().sum()\n",
    "cleaned_duplicates = cleaned_df.duplicated().sum()\n",
    "\n",
    "# Summary of changes\n",
    "summary = f\"\"\"\n",
    "Verification Report for EdStatsSeries.csv\n",
    "----------------------------------------\n",
    "Column names changed: {original_cols - cleaned_cols if original_cols != cleaned_cols else 'No changes'}\n",
    "Total columns before: {len(original_cols)}, after: {len(cleaned_cols)}\n",
    "\n",
    "Missing values before cleaning: {original_missing}\n",
    "Missing values after cleaning: {cleaned_missing}\n",
    "\n",
    "Duplicate rows before cleaning: {original_duplicates}\n",
    "Duplicate rows after cleaning: {cleaned_duplicates}\n",
    "\n",
    "Rows before: {len(original_df)}, after: {len(cleaned_df)}\n",
    "\"\"\"\n",
    "\n",
    "# Save summary to a text file\n",
    "with open(\"verification_summary.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8179d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification Report: EdStatsCountry.csv\n",
      "---------------------------------------\n",
      "Columns before: 32, after: 31\n",
      "Column name changes: {'Alternative conversion factor', 'Balance of Payments Manual in use', 'SNA price valuation', 'Latest population census', 'Latest agricultural census', 'Latest water withdrawal data', 'Long Name', 'Source of most recent Income and expenditure data', 'Lending category', 'Region', 'Income Group', 'IMF data dissemination standard', 'Latest industrial data', 'Latest household survey', 'System of National Accounts', 'Special Notes', 'Other groups', 'External debt Reporting status', 'PPP survey year', 'Country Code', 'Latest trade data', 'National accounts reference year', 'Currency Unit', 'WB-2 code', 'System of trade', 'Vital registration complete', '2-alpha code', 'Table Name', 'Short Name', 'National accounts base year', 'Unnamed: 31', 'Government Accounting concept'}\n",
      "\n",
      "Missing values before: 2354\n",
      "Missing values after: 2113\n",
      "\n",
      "Duplicate rows before: 0\n",
      "Duplicate rows after: 0\n",
      "\n",
      "Rows before: 241, after: 241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "original_file = \"EdStatsCountry.csv\"\n",
    "cleaned_file = \"cleaned_EdStatsCountry.csv\"\n",
    "\n",
    "original_df = pd.read_csv(original_file, low_memory=False)\n",
    "cleaned_df = pd.read_csv(cleaned_file, low_memory=False)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Verification Report: EdStatsCountry.csv\n",
    "---------------------------------------\n",
    "Columns before: {len(original_df.columns)}, after: {len(cleaned_df.columns)}\n",
    "Column name changes: {set(original_df.columns) - set(cleaned_df.columns) if set(original_df.columns) != set(cleaned_df.columns) else 'No changes'}\n",
    "\n",
    "Missing values before: {original_df.isnull().sum().sum()}\n",
    "Missing values after: {cleaned_df.isnull().sum().sum()}\n",
    "\n",
    "Duplicate rows before: {original_df.duplicated().sum()}\n",
    "Duplicate rows after: {cleaned_df.duplicated().sum()}\n",
    "\n",
    "Rows before: {len(original_df)}, after: {len(cleaned_df)}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"verify_EdStatsCountry.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a54dd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification Report: EdStatsCountry-Series.csv\n",
      "----------------------------------------------\n",
      "Columns before: 4, after: 3\n",
      "Column name changes: {'Unnamed: 3', 'CountryCode', 'DESCRIPTION', 'SeriesCode'}\n",
      "\n",
      "Missing values before: 613\n",
      "Missing values after: 0\n",
      "\n",
      "Duplicate rows before: 0\n",
      "Duplicate rows after: 0\n",
      "\n",
      "Rows before: 613, after: 613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "original_file = \"EdStatsCountry-Series.csv\"\n",
    "cleaned_file = \"cleaned_EdStatsCountrySeries.csv\"\n",
    "\n",
    "original_df = pd.read_csv(original_file, low_memory=False)\n",
    "cleaned_df = pd.read_csv(cleaned_file, low_memory=False)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Verification Report: EdStatsCountry-Series.csv\n",
    "----------------------------------------------\n",
    "Columns before: {len(original_df.columns)}, after: {len(cleaned_df.columns)}\n",
    "Column name changes: {set(original_df.columns) - set(cleaned_df.columns) if set(original_df.columns) != set(cleaned_df.columns) else 'No changes'}\n",
    "\n",
    "Missing values before: {original_df.isnull().sum().sum()}\n",
    "Missing values after: {cleaned_df.isnull().sum().sum()}\n",
    "\n",
    "Duplicate rows before: {original_df.duplicated().sum()}\n",
    "Duplicate rows after: {cleaned_df.duplicated().sum()}\n",
    "\n",
    "Rows before: {len(original_df)}, after: {len(cleaned_df)}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"verify_EdStatsCountrySeries.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f47c5f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification Report: EdStatsFootNote.csv\n",
      "----------------------------------------\n",
      "Columns before: 5, after: 4\n",
      "Column name changes: {'SeriesCode', 'Unnamed: 4', 'Year', 'DESCRIPTION', 'CountryCode'}\n",
      "\n",
      "Missing values before: 643638\n",
      "Missing values after: 0\n",
      "\n",
      "Duplicate rows before: 0\n",
      "Duplicate rows after: 0\n",
      "\n",
      "Rows before: 643638, after: 643638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "original_file = \"EdStatsFootNote.csv\"\n",
    "cleaned_file = \"cleaned_EdStatsFootNote.csv\"\n",
    "\n",
    "original_df = pd.read_csv(original_file, low_memory=False)\n",
    "cleaned_df = pd.read_csv(cleaned_file, low_memory=False)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Verification Report: EdStatsFootNote.csv\n",
    "----------------------------------------\n",
    "Columns before: {len(original_df.columns)}, after: {len(cleaned_df.columns)}\n",
    "Column name changes: {set(original_df.columns) - set(cleaned_df.columns) if set(original_df.columns) != set(cleaned_df.columns) else 'No changes'}\n",
    "\n",
    "Missing values before: {original_df.isnull().sum().sum()}\n",
    "Missing values after: {cleaned_df.isnull().sum().sum()}\n",
    "\n",
    "Duplicate rows before: {original_df.duplicated().sum()}\n",
    "Duplicate rows after: {cleaned_df.duplicated().sum()}\n",
    "\n",
    "Rows before: {len(original_df)}, after: {len(cleaned_df)}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"verify_EdStatsFootNote.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076cb556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification Report for EdStatsData.csv\n",
      "----------------------------------------\n",
      "Column names changed: {'Country Code', 'Country Name', 'Indicator Name', 'Unnamed: 69', 'Indicator Code'}\n",
      "Total columns before: 70, after: 69\n",
      "\n",
      "Missing values before cleaning: 53455179\n",
      "Missing values after cleaning: 0\n",
      "\n",
      "Duplicate rows before cleaning: 0\n",
      "Duplicate rows after cleaning: 0\n",
      "\n",
      "Rows before: 886930, after: 357405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "original_file = \"EdStatsData.csv\"\n",
    "cleaned_file = \"cleaned_EdStatsData.csv\"\n",
    "\n",
    "\n",
    "original_df = pd.read_csv(original_file, low_memory=False)\n",
    "cleaned_df = pd.read_csv(cleaned_file, low_memory=False)\n",
    "\n",
    "\n",
    "original_cols = set(original_df.columns)\n",
    "cleaned_cols = set(cleaned_df.columns)\n",
    "\n",
    "\n",
    "original_missing = original_df.isnull().sum().sum()\n",
    "cleaned_missing = cleaned_df.isnull().sum().sum()\n",
    "\n",
    "original_duplicates = original_df.duplicated().sum()\n",
    "cleaned_duplicates = cleaned_df.duplicated().sum()\n",
    "\n",
    "# Summary of changes\n",
    "summary = f\"\"\"\n",
    "Verification Report for EdStatsData.csv\n",
    "----------------------------------------\n",
    "Column names changed: {original_cols - cleaned_cols if original_cols != cleaned_cols else 'No changes'}\n",
    "Total columns before: {len(original_cols)}, after: {len(cleaned_cols)}\n",
    "\n",
    "Missing values before cleaning: {original_missing}\n",
    "Missing values after cleaning: {cleaned_missing}\n",
    "\n",
    "Duplicate rows before cleaning: {original_duplicates}\n",
    "Duplicate rows after cleaning: {cleaned_duplicates}\n",
    "\n",
    "Rows before: {len(original_df)}, after: {len(cleaned_df)}\n",
    "\"\"\"\n",
    "\n",
    "# Save summary to a text file\n",
    "with open(\"verification_EdStatsData.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
